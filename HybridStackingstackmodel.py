# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wj3GDs4ZhXPVEf60ROSRX0n--mYkcif4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# =======================
# Load Dataset
# =======================
df = pd.read_csv("/content/new machine learning data - filtered updated10.csv")

# Standardize column names
df.columns = [c.strip().lower().replace(" ", "_") for c in df.columns]

# Rename if necessary
if 'distance' not in df.columns:
    df.rename(columns={df.columns[0]: 'distance'}, inplace=True)
if 'path_loss' not in df.columns:
    df.rename(columns={df.columns[1]: 'path_loss'}, inplace=True)
if 'env' not in df.columns:
    df.rename(columns={df.columns[2]: 'env'}, inplace=True)

print("Dataset head:\n", df.head())

# =======================
# Train/Test Split
# =======================
X = df[['distance', 'env']]
y = df['path_loss']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# =======================
# Models
# =======================
rf = RandomForestRegressor(n_estimators=200, random_state=42)
gbr = GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=42)

stack_model = StackingRegressor(
    estimators=[
        ('rf', rf),
        ('gbr', gbr),
        ('svr', SVR(kernel='rbf', C=100, gamma=0.1)),
        ('mlp', MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42))
    ],
    final_estimator=LinearRegression(),
    cv=5,
    passthrough=True
)

# =======================
# Fit Models & Collect Metrics
# =======================
models = {
    "Random Forest": rf,
    "Gradient Boosting": gbr,
    "Hybrid Stacking": stack_model
}

results = []
best_model = None
best_r2 = -np.inf

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    results.append([name, r2, mse, rmse, mae])

    # Track best model
    if r2 > best_r2:
        best_r2 = r2
        best_model = (name, model, y_pred)

# =======================
# Results Table
# =======================
results_df = pd.DataFrame(results, columns=["Model", "RÂ² Score", "MSE", "RMSE", "MAE"])
print("\nðŸ“Š Model Comparison Table:")
print(results_df)

# =======================
# Classical Models (for plotting)
# =======================
def fspl(d, f=28e9):
    c = 3e8
    return 20*np.log10(d) + 20*np.log10(f) - 147.55

def ci_model(d, pl_d0=61.4, n=2.1, d0=1.0):
    return pl_d0 + 10*n*np.log10(d/d0)

def fi_model(d, alpha=60, beta=20):
    return alpha + beta*np.log10(d)

def abg_model(d, alpha=40, beta=30, gamma=2.2, f=28):
    return alpha + beta*np.log10(d) + gamma*np.log10(f)

# =======================
# Predictions for LOS/NLOS (Best Model)
# =======================
dist_range = np.linspace(df['distance'].min(), df['distance'].max(), 400)

los_pred = best_model[1].predict(pd.DataFrame({'distance': dist_range, 'env': np.zeros(len(dist_range))}))
nlos_pred = best_model[1].predict(pd.DataFrame({'distance': dist_range, 'env': np.ones(len(dist_range))}))

# Classical models
fspl_vals = fspl(dist_range)
ci_vals   = ci_model(dist_range)
fi_vals   = fi_model(dist_range)
abg_vals  = abg_model(dist_range)

# =======================
# Plotting
# =======================
plt.figure(figsize=(14, 10))

# --- (a) LOS ---
plt.subplot(2, 2, 1)
plt.scatter(df[df['env']==0]['distance'], df[df['env']==0]['path_loss'], alpha=0.4, label='Measured LOS')
plt.plot(dist_range, los_pred, 'k', linewidth=2, label=f'{best_model[0]} LOS')
plt.plot(dist_range, fspl_vals, 'b--', label='FSPL')
plt.plot(dist_range, ci_vals, 'g--', label='CI')
plt.plot(dist_range, fi_vals, 'r--', label='FI')
plt.plot(dist_range, abg_vals, 'm--', label='ABG')
plt.title("(a) LOS Scenario")
plt.xlabel("Distance (m)")
plt.ylabel("Path Loss (dB)")
plt.legend()

# --- (b) NLOS ---
plt.subplot(2, 2, 2)
plt.scatter(df[df['env']==1]['distance'], df[df['env']==1]['path_loss'], alpha=0.4, label='Measured NLOS')
plt.plot(dist_range, nlos_pred, 'k', linewidth=2, label=f'{best_model[0]} NLOS')
plt.plot(dist_range, fspl_vals, 'b--', label='FSPL')
plt.plot(dist_range, ci_vals, 'g--', label='CI')
plt.plot(dist_range, fi_vals, 'r--', label='FI')
plt.plot(dist_range, abg_vals, 'm--', label='ABG')
plt.title("(b) NLOS Scenario")
plt.xlabel("Distance (m)")
plt.ylabel("Path Loss (dB)")
plt.legend()

# --- (c) Extended LOS ---
plt.subplot(2, 2, 3)
plt.scatter(df[df['env']==0]['distance'], df[df['env']==0]['path_loss'], alpha=0.4, label='Measured LOS')
plt.plot(dist_range, los_pred, 'k', linewidth=2, label=f'{best_model[0]} LOS')
plt.title("(c) Extended LOS")
plt.xlabel("Distance (m)")
plt.ylabel("Path Loss (dB)")
plt.legend()

# --- (d) Extended NLOS ---
plt.subplot(2, 2, 4)
plt.scatter(df[df['env']==1]['distance'], df[df['env']==1]['path_loss'], alpha=0.4, label='Measured NLOS')
plt.plot(dist_range, nlos_pred, 'k', linewidth=2, label=f'{best_model[0]} NLOS')
plt.title("(d) Extended NLOS")
plt.xlabel("Distance (m)")
plt.ylabel("Path Loss (dB)")
plt.legend()

plt.tight_layout()
plt.show()

# =======================
# Predicted vs Actual for Best Model
# =======================
y_pred_best = best_model[2]

plt.figure(figsize=(7,6))
plt.scatter(y_test, y_pred_best, alpha=0.6, edgecolor='k')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title(f"Predicted vs Actual ({best_model[0]})")
plt.xlabel("Actual Path Loss (dB)")
plt.ylabel("Predicted Path Loss (dB)")
plt.grid(True)
plt.show()